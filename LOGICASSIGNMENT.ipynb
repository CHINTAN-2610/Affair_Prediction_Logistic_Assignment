{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee93b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6defe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66194f85",
   "metadata": {},
   "source": [
    "## Module 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c1d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class operationOS:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def currentDirec(self):\n",
    "        self.path = os.getcwd()\n",
    "        return self.path\n",
    "    \n",
    "    def newFolder(self,dirName):\n",
    "        '''\n",
    "        Return path for created new folder\n",
    "        \n",
    "        '''\n",
    "        self.dirName = dirName\n",
    "        self.path = operationOS().currentDirec()\n",
    "        self.new_path = os.path.join(self.path,self.dirName)\n",
    "        if not os.path.isdir(self.new_path):\n",
    "            os.makedirs(self.new_path)\n",
    "            \n",
    "        return self.new_path\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2589f",
   "metadata": {},
   "source": [
    "## Module 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def removeColumn(self,data,columnName):\n",
    "        \"\"\" \n",
    "        This mehod remove column mentioned from dataset name mentioned\n",
    "        column : string indicating column name\n",
    "        data : varibale name of dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.column = columnName\n",
    "        self.new_data = self.data.drop(self.column , axis = 1)\n",
    "        \n",
    "        return self.new_data\n",
    "    \n",
    "    def labelDefine(self,data,columnName,new_columnName):\n",
    "        \"\"\"\n",
    "        This is method define label to affair dataset\n",
    "        column : last columns from label should define\n",
    "        data : dataset into which label should define\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.column = columnName\n",
    "        self.new_column = new_columnName\n",
    "        self.data[self.new_column] = np.where(self.data[self.column]>0 ,1,0)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def ReportMissingValue(self,FolderName,Filename,data):\n",
    "        \"\"\"\n",
    "        This method make txt file in which information regrarding missing value \n",
    "        for each columns mentioned at given folder name and filename\n",
    "        \n",
    "        \"\"\"\n",
    "        self.FolderName = FolderName\n",
    "        self.Filename   = Filename\n",
    "        self.data = data\n",
    "        \n",
    "        self.objectFolder = operationOS().newFolder(self.FolderName)\n",
    "        \n",
    "        file = os.path.join(self.objectFolder,self.Filename)\n",
    "        \n",
    "        for k,i in enumerate(self.data.isnull().sum()):\n",
    "            with open(file , \"a\") as f:\n",
    "                f.write(self.data.isnull().sum().index[k] + \"...........\" + str(i) + \"\\n\")\n",
    "        \n",
    "        \n",
    "    def ReplaceMissing(self,data):\n",
    "        \"\"\"\n",
    "        For now replacing missing values using median if any present\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        for column in self.data.columns:\n",
    "            self.data[column] = np.where(self.data[column] == np.nan , self.data[column].median() , self.data[column])\n",
    "            \n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cb3ba",
   "metadata": {},
   "source": [
    "## Module 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4986a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "    \n",
    "    def __init__(self,model_folder,scaler_file):\n",
    "        self.model_folder = model_folder\n",
    "        self.scaler_file = scaler_file\n",
    "        objectModel = operationOS()\n",
    "        self.newFolder  = objectModel.newFolder(self.model_folder)\n",
    "        self.filename = self.scaler_file + \".sav\"\n",
    "        self.modelpath = os.path.join(self.newFolder,self.filename)\n",
    "        \n",
    "    def TrainTest(self,data):\n",
    "        self.data = data\n",
    "        self.train , self.test = train_test_split(self.data , test_size = 0.30 , random_state = 42)\n",
    "        return self.train , self.test\n",
    "    \n",
    "    def Featurelabel(self,data):\n",
    "        self.data = data\n",
    "        self.feature = self.data.iloc[:,0:self.data.shape[1]-1]\n",
    "        self.label = self.data.iloc[:,-1]\n",
    "        return self.feature, self.label\n",
    "    \n",
    "    def transferFeatureTrain(self,features):\n",
    "        self.features = features\n",
    "        scaller = StandardScaler()\n",
    "        self.x_train = scaller.fit_transform(self.features)\n",
    "        pickle.dump(scaller,open(self.modelpath ,\"wb\"))\n",
    "        return self.x_train\n",
    "    \n",
    "    def transferFeatureTest(self,features):\n",
    "        self.features = features\n",
    "        scaller = pickle.load(open(self.modelpath,\"rb\"))\n",
    "        self.x_test = scaller.transform(self.features)\n",
    "        return self.x_test\n",
    "         \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94ff4c",
   "metadata": {},
   "source": [
    "## Module 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28e7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training(DataSplit):\n",
    "    \n",
    "    def __init__(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def modelTraining(self):\n",
    "        \n",
    "        logi1  = LogisticRegression(verbose=1 ,n_jobs=4, penalty = 'l2',solver='lbfgs' )\n",
    "        logi2  = LogisticRegression(verbose=1 ,n_jobs=4 ,penalty = 'l1',solver='liblinear' ) \n",
    "        logi3  = LogisticRegression(verbose=1 ,n_jobs=4 ,penalty = 'l2',solver='liblinear' )\n",
    "        logi4  = LogisticRegression(verbose=1 ,n_jobs=4 ,solver='newton-cg' )\n",
    "        logi5  = LogisticRegression(verbose=1 ,n_jobs=4 ,solver='liblinear' )\n",
    "        logi6  = LogisticRegression(verbose=1 ,n_jobs=4 ,penalty = 'none',solver='sag')\n",
    "        \n",
    "        logi1.fit(self.x_train,self.y_train)\n",
    "        logi2.fit(self.x_train,self.y_train)\n",
    "        logi3.fit(self.x_train,self.y_train)\n",
    "        logi4.fit(self.x_train,self.y_train)\n",
    "        logi5.fit(self.x_train,self.y_train)\n",
    "        logi6.fit(self.x_train,self.y_train)\n",
    "        \n",
    "        y_predi_logi1 = logi1.predict(self.x_test)\n",
    "        y_predi_logi2 = logi2.predict(self.x_test)\n",
    "        y_predi_logi3 = logi3.predict(self.x_test)\n",
    "        y_predi_logi4 = logi4.predict(self.x_test)\n",
    "        y_predi_logi5 = logi5.predict(self.x_test)\n",
    "        y_predi_logi6 = logi6.predict(self.x_test)\n",
    "        \n",
    "        auc_logi1 = roc_auc_score(y_test, y_predi_logi1)\n",
    "        auc_logi2 = roc_auc_score(y_test, y_predi_logi2)\n",
    "        auc_logi3 = roc_auc_score(y_test, y_predi_logi3)\n",
    "        auc_logi4 = roc_auc_score(y_test, y_predi_logi4)\n",
    "        auc_logi5 = roc_auc_score(y_test, y_predi_logi5)\n",
    "        auc_logi6 = roc_auc_score(y_test, y_predi_logi6)\n",
    "        \n",
    "        list_model_auc = [auc_logi1,auc_logi2,auc_logi3,auc_logi4,auc_logi5,auc_logi6]\n",
    "        list_model = [logi1,logi2,logi3,logi4,logi5,logi6]\n",
    "        \n",
    "        finalized_model = list_model[list_model_auc.index(max(list_model_auc))]\n",
    "        \n",
    "        super().__init__(\"Models\",\"Logistic\")\n",
    "        \n",
    "        pickle.dump(finalized_model,open(self.modelpath ,\"wb\"))\n",
    "        \n",
    "        return \"AUC SCORE = {}\".format(max(list_model_auc)) + \"......\" + \"Accuracy = {}\".format(finalized_model.score(self.x_test, self.y_test))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689592e",
   "metadata": {},
   "source": [
    "## Module 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68f04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(DataSplit):\n",
    "    \n",
    "    def __init__(self,x_train,y_train,x_test,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def RandomData(self,featuresList):\n",
    "        self.featuresList = featuresList\n",
    "        predictObject = DataSplit(\"Models\",\"scaler\")\n",
    "        featureVector = predictObject.transferFeatureTest(self.featuresList)\n",
    "        \n",
    "        super().__init__(\"Models\",\"Logistic\")\n",
    "        \n",
    "        modelPredict = pickle.load(open(self.modelpath ,\"rb\"))\n",
    "        output = modelPredict.predict(featureVector)\n",
    "        \n",
    "        if output == 0:\n",
    "            return \"You are safe! , No affairs\"\n",
    "        else:\n",
    "            return \"Ohh jesus!! Blessed me\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351ec31",
   "metadata": {},
   "source": [
    "## app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b0065",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc1c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = sm.datasets.fair.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be782b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = preprocessing().labelDefine(dta,\"affairs\",\"affair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7d54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = preprocessing().removeColumn(dta,\"affairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d889b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing().ReportMissingValue(\"Report\",\"MissingInfo\",data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b29c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = preprocessing().ReplaceMissing(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50fe69",
   "metadata": {},
   "source": [
    "#### Preparing Feature abd label vectro for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdecc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , test = DataSplit(\"Models\",\"scaler\").TrainTest(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a49b4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train= DataSplit(\"Models\",\"scaler\").Featurelabel(train)\n",
    "X_test , y_test = DataSplit(\"Models\",\"scaler\").Featurelabel(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e93a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = DataSplit(\"Models\",\"scaler\").transferFeatureTrain(X_train)\n",
    "x_test = DataSplit(\"Models\",\"scaler\").transferFeatureTest(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c4d81",
   "metadata": {},
   "source": [
    "#### Training model as per following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b560c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "C:\\Users\\CHINTAN PATEL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1535: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "C:\\Users\\CHINTAN PATEL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1535: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear]convergence after 33 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\CHINTAN PATEL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1535: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AUC SCORE = 0.6336699089084454......Accuracy = 0.7214659685863875'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingModel = Training(x_train,y_train,x_test,y_test)\n",
    "trainingModel.modelTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386716b",
   "metadata": {},
   "source": [
    "#### Prediction of random featurevector as per given order of feture inside main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6417a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are safe! , No affairs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictModel = Prediction(x_train,y_train,x_test,y_test)\n",
    "predictModel.RandomData(dta.iloc[3:4,:dta.shape[1]-2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53dd878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
